<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" type="text/css" href="http://www.quantisan.com/theme/css/style.css">
    <link rel="stylesheet" type="text/css" href="http://www.quantisan.com/theme/css/pygments.css">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:800,400,300|Inconsolata' rel='stylesheet' type='text/css'>
	<link href="http://www.quantisan.com/" type="application/atom+xml" rel="alternate" title="Quantitative Artisan ATOM Feed" />


        <title>Quantitative Artisan</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Paul Lam">
</head>

<body>
    <section id="navbar">
        <div class="user_meta">
            <h1 id="user"><a href="http://www.quantisan.com" class="">Paul Lam</a></h1>
            <h2>Data. Engineering. Startup.</h2>
        </div>
        <div class="nav-button">
            <ul>
                                    <li><a href="http://www.quantisan.com/about/">About</a></li>
                            <li><a href="mailto:paul@quantisan.com">Email</a></li>
                            <li><a href="http://www.twitter.com/Quantisan">Twitter</a></li>
                            <li><a href="http://www.github.com/Quantisan">Github</a></li>
                            <li><a href="http://www.linkedin.com/in/paullam">LinkedIn</a></li>
                            <li><a href="http://feeds.feedburner.com/Quantisan">Subscribe</a></li>
             </ul>
         </div>
     </section>

     <section id="sidebar">
        <img src="/images/profile_circle.png" id="logo" alt="logo">

        <div class="user_meta">
            <h1 id="user"><a href="http://www.quantisan.com" class="">Paul Lam</a></h1>
            <h2>Data. Engineering. Startup.</h2>
            <ul>
                        <li><a href="http://www.quantisan.com/about/">About</a></li>
                        <li><a href="mailto:paul@quantisan.com">Email</a></li>
                        <li><a href="http://www.twitter.com/Quantisan">Twitter</a></li>
                        <li><a href="http://www.github.com/Quantisan">Github</a></li>
                        <li><a href="http://www.linkedin.com/in/paullam">LinkedIn</a></li>
                        <li><a href="http://feeds.feedburner.com/Quantisan">Subscribe</a></li>
            </ul>
        </div>
        <footer>
            <address>
                Powered by <a href='http://docs.getpelican.com/en/latest/'>Pelican</a>,
                <a href='https://github.com/jamescooke/pelican-svbtle#readme'>theme info</a>.
            </address>
        </footer>
    </section>

    <section id="posts">
	
        <article class='listed'>
            <h1 class="title">
                <a href="http://www.quantisan.com/what-i-learned-from-2-years-of-data-sciencing/" rel='bookmark'>What I learned from 2 years of 'data sciencing'</a>
            </h1>
            <div class="article-content"> <p>Last week was my last day at uSwitch.com. From becoming aware of <em>data scientist</em> as a valid job title on my job offer letter, to speaking at Strata London, to signing a book deal to write about it in our book on Web Data Mining (that's progressing at a glacial pace), I figured that I should jot down some takeaway lessons while this experience is still fresh.</p>
<blockquote class="twitter-tweet" lang="en"><p>sad day today as <a href="https://twitter.com/uSwitchEng">@uSwitchEng</a> had to say goodbye to the amazing <a href="https://twitter.com/Quantisan">@Quantisan</a>. you will be missed and best of luck in the next great adventure!</p>&mdash; Tim Goodwin (@timrgoodwin) <a href="https://twitter.com/timrgoodwin/statuses/413388484011753472">December 18, 2013</a></blockquote>

<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<h2>It is not about the <em>science</em>. It is about the <em>data</em>.</h2>
<p>In my first year our team delivered a handful of data projects. To name just a few, we developed a dashboard showing lifetime values for all of our millions of customers, demonstrating a 6% revenue gain with a product showcase sorting algorithm modelled by the multi-armed bandit problem, and simulated offline advertising impacts to online sales for optimising marketing spending saving Â£20,000 a month. For various reasons, none of these projects gained traction within the company and became abandoned.</p>
<p>Much of the efforts spent for those projects were in getting the right data into the right shape. We needed to capture events across applications on different technology stacks, associate individual events to unique customers, and being able to process all those data in an ad-hoc manner. Over the course of my first year, our team of 2 built and evolved a distributed data architecture and scalable data workflow that's based on open source tools and publications from companies like Google, LinkedIn, Twitter, etc. In fact, I scratched enough of my own itch on an open source big data processing project to become one of the maintainers for it.</p>
<blockquote class="twitter-tweet" lang="en"><p>Congratulations to <a href="https://twitter.com/Quantisan">@Quantisan</a> for becoming a Cascalog committer today</p>&mdash; Nathan Marz (@nathanmarz) <a href="https://twitter.com/nathanmarz/statuses/312304668975980545">March 14, 2013</a></blockquote>

<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>On a rather "by the way" note, we structured lifetime views of customer data from the disparate signals across company verticals. Words had been going around the company that we had this new business intelligence tool, more and more people asked us to help them answer questions with data on their side of the business. The data we surfaced from our data workflow satisfied a wide-spread need in the company to understand customer behaviours. Little did I know that we'll be cleaning and shaping data for most of my second year at uSwitch. Months later to recent times, our commercial team released an external data product that I can't say much but might bring in sizable benefits for the company soon.</p>
<p>It is glamorous to talk about the latest and greatest machine learning or data visualisation. In practice, I was just cleaning and shaping data. Enabling more people to make use of deep and structured data was what delivered value to the company.</p>
<h2>Figuring out the right problems to solve is not easy.</h2>
<p>Had we known that customer behaviour analytics are so valuable, we would have done it earlier on (although many of the other projects were definitely a lot of fun to do). Figuring out the right work to do is one of the most difficult tasks for a data science team. It doesn't help with the fact that the data science role is so vague. Marketing think we are mining for customer insights. Developers think we're toying with Riemann, Storm, or something bleeding edge. Product managers think we are plotting graphs.</p>
<p>Everyone has ideas but there were only 3 of us in the team. Figuring out where to devote our time and effort is not as easy as it sounds. The issue is that a new project can be almost anything. So which <em>one</em> should we do? The paradox of choice can be confusing.</p>
<p>Seeing that this is data science, why not dive right into the data like they would often say in hackathons? I made the mistake in the first few weeks in my data science career just hacking away with the data and then trying to persuade people to make use of the result ... somehow.</p>
<p>Some interesting graphs came about. But as <a href="https://twitter.com/dancingmango">Marc</a> often like to ask, "so what?" Unless someone or something can act on the data, results can only satisfy intellectual curiosity. A business can't survive on funding people to carry out academic studies forever.</p>
<p>Nowadays, we talk to different stakeholders to try to dig as deep as possible into their needs before any code is written for a new project. This is me handwaving. Frankly, I'm still learning my way and rely a lot on luck through trials and errors to discoverying the right problems to solve.</p>
<h2>It is a humbling experience.</h2>
<p>Working with <a href="http://oobaloo.co.uk/">Paul Ingles</a> and <a href="http://uk.linkedin.com/pub/abigail-lebrecht/2/95a/42">Abigail Lebrecht</a> has been frustratingly awesome. Paul is opinionated about doing things as simple as possible. On more occasions than I can remember, we implemented our own little Clojure libraries because the open source ones available were "trying to do too much". Abigail is adamant about getting the data and analyses right. "What do you mean this data is only 99% correct?" Working day in and day out with Paul and Abigail showed that I had much to learn in efficient problem solving and to question all hidden assumptions.</p>
<p>In my previous role as a biomedical engineer, I also had the opportunity to work in a multidisciplinary team. But for my <a href="http://www.biomedcentral.com/content/pdf/1743-0003-5-15.pdf">haptic-robotic therapy project</a>, I never even considered going into a workshop to build my robot or provide clinical therapy for the stroke patients. What multidisciplinary meant back then were a small group of professionals coming together to work on a project with each person doing different tasks to get the thing to work.</p>
<p>The advantage of being a data scientist is that I was very hands-on in all aspects of the work. One week I might be pair programming with Paul, and fighting to keep him away from my keyboard, to integrate Riemann for monitoring our data architecture. Other days I am debating with Abigail on the data mining side. Which usually resulted from her finding flaws in the materialised tables that I produced from Cascalog, and then having to come up with a better estimation model for the missing data.</p>
<h2>So do you want to be a data scientist?</h2>
<p>This is it for me formally as a data scientist. I am moving back across the Atlantic to the states to cofound a new venture and continuing my journey <a href="http://www.sourceful.io">to make information accessible</a>. However, back to the topic at hand. If cleaning vast amount of data, being clueless as to what to do, and debating with colleagues sound like a challenge that you want to take on, I know a company in London that's <a href="http://www.uswitch.com/careers/">looking for a data scientist</a>!</p> </div>
            <div class="abbr published">
                Posted  <a href='http://www.quantisan.com/what-i-learned-from-2-years-of-data-sciencing/' title='2013-12-21T00:00:00'>21 December 2013</a> in <a href="http://www.quantisan.com/category/data-science/">data-science</a>.              
            </div>
        </article>
        <article class='listed'>
            <h1 class="title">
                <a href="http://www.quantisan.com/post-gone-viral-16000-visitors-in-a-day-how-many-actually-read-the-article/" rel='bookmark'>Post gone viral, 16000 visitors in a day, how many actually read the article?</a>
            </h1>
            <div class="article-content"> <p>Edit: A few people have <a href="https://news.ycombinator.com/item?id=5693881">pointed out</a> that my assumption about the Analytics engagement metric <em>might be</em> wrong because single page hit <em>could be</em> counted as zero on engagement time. I'll make an update to this post when smarter people than me on HN can agree on a metric. So I open this problem to Analytics expert, how can I discern readership ratio from Analytics data?</p>
<p>My reminiscing post about <a href="/how-a-few-screws-cost-2000-and-a-240gb-multinodes-cluster-cost-50/">my time as an aerospace engineer versus software</a> was on the front page of Hacker News for about 12 hours on Friday. That garnered 16,374 unique visitors to this site on that single day. However, Google Analytics data say that only 975 of those people spent more than 10 seconds here. Given that there's 652 words in that viral post, I doubt anyone can actually read it within that time. If we assume that only people spending more than 10 seconds have meaningfully read the article, it appears that only 6% of traffic are <em>real</em> readers from this Hacker News blitz.</p>
<p><img alt="Viral post visitors engagement" src="http://www.quantisan.com/images/2013/10052013_analytics_engagement.png" /></p>
<p>Given that my usual stats is above 10%, viral traffic audience is understandably less targeted but isn't abysmal by comparison. However, as a data scientist, I'm obliged to say that as this is an one-off event, we couldn't draw a statistically significant observation from it.</p>
<p>Interestingly, overall traffic the day after on Saturday is back down to 901 visits. And engagement for those spending more than 10 seconds is up at 8.3%. These residual traffic are coming in from domains like Twitter and link sharers.</p> </div>
            <div class="abbr published">
                Posted  <a href='http://www.quantisan.com/post-gone-viral-16000-visitors-in-a-day-how-many-actually-read-the-article/' title='2013-05-12T11:30:00'>12 May 2013</a> in <a href="http://www.quantisan.com/category/data-science/">data-science</a>.              
            </div>
        </article>
        <article class='listed'>
            <h1 class="title">
                <a href="http://www.quantisan.com/unconfusing-false-positive-and-false-negative-statistical-errors-confusion/" rel='bookmark'>Unconfusing false-positive and false-negative statistical errors confusion</a>
            </h1>
            <div class="article-content"> <p>I was reading a blog post <a href="http://mcfunley.com/whom-the-gods-would-destroy-they-first-give-real-time-analytics">about real-time analytics</a> over the lunch today. In it, the author made a claim that "funny business with timeframes can coerce most A/B tests into statistical significance." There's also <a href="http://mcfunley.com/static/811609fd0f3/images/real-time-screwed.png">this plot illustrating two time series of the cumulative number of heads in a two-fair-coin-comparison</a>. Yet, time nor ordering has an effect on test results because each flip is independent. Not content with his claim, I wrote a coin flipping simulation in R to prove him wrong.</p>
<p>This plot shows p-values of proportion tests for two simulated fair coin flips that they are different. Each of these tests are repeated with increasing number of flips per test. Since both coins are fair, we should expect no p-value should dip below our 95% significance level (red horizontal line). Yet we're seeing some false positives (i.e. a claim of evidence when there really isn't) that say the two coins are statistically different.</p>
<p><img alt="false positive vs sample size, up to N=1000" src="http://www.quantisan.com/images/2013/coin-false-positives-increasing-1000.png" /></p>
<p>A better illustration is to run a test with 1000 flips, get a test result, and repeat many times for many results. We see that sometimes false positive happens. Given that our significance level is 95%, we can expect false positives to happen 1 in 20 times.</p>
<p><img alt="repeated sampling at 1000 flips" src="http://www.quantisan.com/images/2013/coin-false-positives-1000-only.png" /></p>
<p>Remembering that I should do a power calculation to get an optimal sample size, doing <code>power.prop.test(p1=0.5, p2=0.501, power=0.90, alternative="two.sided")</code> says N should be 5253704.</p>
<p>So this is a plot of doing many tests with 5253704 flips each.</p>
<p><img alt="N=5253704" src="http://www.quantisan.com/images/2013/coin-false-positives-power.png" /></p>
<p>But the false positives didn't improve at all! By now, I'm quite confused. So, I asked for help on StackExchange and received <a href="http://stats.stackexchange.com/q/47434/3847">this insight</a>.</p>
<div class="highlight"><pre><span class="n">What</span><span class="err">&#39;</span><span class="n">s</span> <span class="n">being</span> <span class="n">gained</span> <span class="n">by</span> <span class="n">running</span> <span class="n">more</span> <span class="n">trials</span> <span class="n">is</span> <span class="n">an</span> <span class="n">increase</span>
<span class="n">in</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="nb">true</span> <span class="n">positives</span> <span class="n">or</span><span class="p">,</span> <span class="n">equivalently</span><span class="p">,</span> <span class="n">a</span> <span class="n">decrease</span>
<span class="n">in</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="nb">false</span> <span class="n">negatives</span><span class="p">.</span> <span class="n">That</span> <span class="n">the</span> <span class="n">number</span> <span class="n">of</span> <span class="nb">false</span>
<span class="n">positives</span> <span class="n">does</span> <span class="n">not</span> <span class="n">change</span> <span class="n">is</span> <span class="n">precisely</span> <span class="n">the</span> <span class="n">guarantee</span> <span class="n">of</span> <span class="n">the</span> <span class="n">test</span><span class="p">.</span>
</pre></div>


<p>And so, a 95% significance level remains 95% significant (1 in 20 chance of false positive) regardless of increasing sample sizes as shown. Again. </p>
<p><img alt="false positive up to 10k trials" src="http://www.quantisan.com/images/2013/coin-false-positive.png" /></p>
<p>What is, in fact, gained for increasing sample size is reduced false negative, which is defined as failing to make a claim when it is there. To illustrate that, we need a different plot because it is an entirely different circumstance. We have two new coins, and they are different. </p>
<p>Say we have one fair (p=50%) coin and another that's slightly biased (p=51%). This plot shows the result of running the same proportion test to see if these two are statistically different. As we increase sample size, the amount of false negative results, points <em>above</em> the red line (0.05 p-value, 95% significance level) denoting negative results, are clearly reduced as sample size increases. Thus this plot is illustrating that false negatives decreases as sample size increases.</p>
<p><img alt="false negative increasing samples" src="http://www.quantisan.com/images/2013/coin-false-negative.png" /></p>
<p>"Funny business" do not coerce A/B tests into statistical significance. The fact that a 95% significance gives 1 in 20 false positives is in fact what it guarantees. To decrease false positive, simply test at a higher significance level. For example, <code>prop.test(c(heads.A, heads.B), n=c(N, N), alternative="two.sided", conf.level=0.99)</code> to set it to 99% instead of the default 95%.</p>
<p>The R source code for this mental sojourn are available at <a href="https://gist.github.com/4502739">this gist on Github</a>.</p> </div>
            <div class="abbr published">
                Posted  <a href='http://www.quantisan.com/unconfusing-false-positive-and-false-negative-statistical-errors-confusion/' title='2013-01-10T22:28:00'>10 January 2013</a> in <a href="http://www.quantisan.com/category/data-science/">data-science</a>.              
            </div>
        </article>
        <article class='listed'>
            <h1 class="title">
                <a href="http://www.quantisan.com/recommendation-discovery-via-graph-traversal/" rel='bookmark'>Recommendation discovery via graph traversal</a>
            </h1>
            <div class="article-content"> <p>I am quite excited about graph computing these days. It represents relational data such as customer behaviour naturally and otherwise complicated problems break down to simple pattern matching algorithm. Take recommendation system, for example. One way to do it is by machine learning as <a href="http://en.wikipedia.org/wiki/Recommender_system">Wikipedia suggests</a>. But if we represent the data in a property graph, a simplistic solution surfaces intuitively. </p>
<p>Picture this. If Bob likes item A; Cathy likes both item A and item B; then we can make the commutative link of item B for Bob.</p>
<p>Let's try it out in <a href="http://www.neo4j.org">Neo4j</a> using <a href="http://console.neo4j.org/?id=2096v6">this pre-built web console example</a>. You should see this graph with 4 person and 5 food items.</p>
<p><img alt="simple graph" src="/static/images/2012/simple_graph.png" /></p>
<p>Using this <a href="http://docs.neo4j.org/chunked/milestone/cypher-query-lang.html">Cypher query</a>, we get a list of all users and what food they like.</p>
<div class="highlight"><pre><span class="n">START</span>   <span class="n">user</span> <span class="o">=</span> <span class="n">node</span><span class="o">:</span><span class="n">node_auto_index</span><span class="p">(</span><span class="n">type</span> <span class="o">=</span> <span class="s">&quot;user&quot;</span><span class="p">)</span> 
<span class="n">MATCH</span>   <span class="n">person</span><span class="o">-</span><span class="p">[</span><span class="o">:</span><span class="n">IS_A</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">user</span><span class="p">,</span> <span class="n">person</span><span class="o">-</span><span class="p">[</span><span class="o">:</span><span class="n">LIKE</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">x</span>
<span class="n">RETURN</span>  <span class="n">person</span><span class="p">.</span><span class="n">name</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">name</span>
</pre></div>


<p>The second line is where we <code>match</code> the pattern that <code>person is a user</code> and that <code>person like x</code>. This query reads almost like the question which we want to ask.</p>
<p>We return all the person and those food they like, <code>x</code>:</p>
<div class="highlight"><pre><span class="o">+------------------------+</span>
<span class="o">|</span> <span class="n">person</span><span class="p">.</span><span class="n">name</span> <span class="o">|</span> <span class="n">x</span><span class="p">.</span><span class="n">name</span>   <span class="o">|</span>
<span class="o">+------------------------+</span>
<span class="o">|</span> <span class="s">&quot;Andy&quot;</span>      <span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Andy&quot;</span>      <span class="o">|</span> <span class="s">&quot;orange&quot;</span> <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Andy&quot;</span>      <span class="o">|</span> <span class="s">&quot;bread&quot;</span>  <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Bob&quot;</span>       <span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Bob&quot;</span>       <span class="o">|</span> <span class="s">&quot;bread&quot;</span>  <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Cat&quot;</span>       <span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Cat&quot;</span>       <span class="o">|</span> <span class="s">&quot;orange&quot;</span> <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Cat&quot;</span>       <span class="o">|</span> <span class="s">&quot;bread&quot;</span>  <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Cat&quot;</span>       <span class="o">|</span> <span class="s">&quot;fish&quot;</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Doug&quot;</span>      <span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;Doug&quot;</span>      <span class="o">|</span> <span class="s">&quot;orange&quot;</span> <span class="o">|</span>
<span class="o">+------------------------+</span>
</pre></div>


<p>Taking this a step further, we can find all the top common <code>x</code> and <code>y</code> that people like together in the above graph.</p>
<div class="highlight"><pre>START   food <span class="o">=</span> node<span class="o">:</span>node_auto_index<span class="p">(</span>type <span class="o">=</span> <span class="s">&quot;food&quot;</span><span class="p">),</span> user <span class="o">=</span> node<span class="o">:</span>node_auto_index<span class="p">(</span>type <span class="o">=</span> <span class="s">&quot;user&quot;</span><span class="p">)</span> 
MATCH   food<span class="o">&lt;-</span><span class="p">[</span><span class="o">:</span>IS_A<span class="p">]</span><span class="o">-</span>x<span class="o">&lt;-</span><span class="p">[</span><span class="o">:</span>LIKE<span class="p">]</span><span class="o">-</span>person<span class="o">-</span><span class="p">[</span><span class="o">:</span>IS_A<span class="p">]</span><span class="o">-&gt;</span>user<span class="p">,</span>
        person<span class="o">-</span><span class="p">[</span><span class="o">:</span>LIKE<span class="p">]</span><span class="o">-&gt;</span>y<span class="o">-</span><span class="p">[</span><span class="o">:</span>IS_A<span class="p">]</span><span class="o">-&gt;</span>food
WHERE   NOT x <span class="o">=</span> y
RETURN  x.name<span class="p">,</span> y.name<span class="p">,</span> count<span class="p">(</span><span class="o">*</span><span class="p">)</span> as cnt 
ORDER BY cnt DESC 
LIMIT <span class="m">10</span><span class="p">;</span>
</pre></div>


<p>Resulting in:</p>
<div class="highlight"><pre><span class="o">+---------------------------+</span>
<span class="o">|</span> <span class="n">x</span><span class="p">.</span><span class="n">name</span>   <span class="o">|</span> <span class="n">y</span><span class="p">.</span><span class="n">name</span>   <span class="o">|</span> <span class="n">cnt</span> <span class="o">|</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span> <span class="s">&quot;orange&quot;</span> <span class="o">|</span> <span class="mi">3</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span> <span class="s">&quot;bread&quot;</span>  <span class="o">|</span> <span class="mi">3</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;orange&quot;</span> <span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span> <span class="mi">3</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;bread&quot;</span>  <span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span> <span class="mi">3</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;bread&quot;</span>  <span class="o">|</span> <span class="s">&quot;orange&quot;</span> <span class="o">|</span> <span class="mi">2</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;orange&quot;</span> <span class="o">|</span> <span class="s">&quot;bread&quot;</span>  <span class="o">|</span> <span class="mi">2</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;fish&quot;</span>   <span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span> <span class="mi">1</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;fish&quot;</span>   <span class="o">|</span> <span class="s">&quot;bread&quot;</span>  <span class="o">|</span> <span class="mi">1</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;apple&quot;</span>  <span class="o">|</span> <span class="s">&quot;fish&quot;</span>   <span class="o">|</span> <span class="mi">1</span>   <span class="o">|</span>
<span class="o">|</span> <span class="s">&quot;bread&quot;</span>  <span class="o">|</span> <span class="s">&quot;fish&quot;</span>   <span class="o">|</span> <span class="mi">1</span>   <span class="o">|</span>
<span class="o">+---------------------------+</span>
</pre></div>


<p>So we find that a lot uf users that likes apple also likes orange or bread. We can then pick out all the people that likes <code>apple</code> but not <code>orange</code> yet to suggest (read: spam) <code>orange</code> to them.</p>
<div class="highlight"><pre><span class="n">START</span>   <span class="n">apple</span> <span class="o">=</span> <span class="n">node</span><span class="o">:</span><span class="n">node_auto_index</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s">&quot;apple&quot;</span><span class="p">),</span> <span class="n">orange</span> <span class="o">=</span> <span class="n">node</span><span class="o">:</span><span class="n">node_auto_index</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s">&quot;orange&quot;</span><span class="p">)</span>
<span class="n">MATCH</span>   <span class="n">person</span><span class="o">-</span><span class="p">[</span><span class="o">:</span><span class="n">LIKE</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">apple</span>
<span class="n">WHERE</span>   <span class="n">NOT</span><span class="p">(</span><span class="n">person</span><span class="o">-</span><span class="p">[</span><span class="o">:</span><span class="n">LIKE</span><span class="p">]</span><span class="o">-&gt;</span><span class="n">orange</span><span class="p">)</span>
<span class="n">RETURN</span>  <span class="n">person</span><span class="p">.</span><span class="n">name</span>

<span class="o">+-------------+</span>
<span class="o">|</span> <span class="n">person</span><span class="p">.</span><span class="n">name</span> <span class="o">|</span>
<span class="o">+-------------+</span>
<span class="o">|</span> <span class="s">&quot;Bob&quot;</span>       <span class="o">|</span>
<span class="o">+-------------+</span>
</pre></div>


<p>Easy, yes?</p> </div>
            <div class="abbr published">
                Posted  <a href='http://www.quantisan.com/recommendation-discovery-via-graph-traversal/' title='2012-11-14T22:31:00'>14 November 2012</a> in <a href="http://www.quantisan.com/category/data-science/">data-science</a>.              
            </div>
        </article>
        <article class='listed'>
            <h1 class="title">
                <a href="http://www.quantisan.com/i-construct-models-not-theories/" rel='bookmark'>I construct models, not theories</a>
            </h1>
            <div class="article-content"> <p>I <a href="http://www.quantisan.com/my-talk-at-or54-on-knowledge-discovery-with-web-log-data/">gave a talk</a> at the 54th Annual Conference on Operational Research last week in Edinburgh. Operational Research is "using advanced analytical methods to help make better decisions" [<a href="https://en.wikipedia.org/wiki/Operation_research">wiki</a>]. This field has been around long before data science and business intelligence. After listening to so many talks and talking to so many academics from marketing to finance to industrial engineering, I find that what we do are quite similar on a 30 thousand feet level -- using data to solve problems. Yet, there is a fundamental difference to our approaches. Whereas operational research is about constructing analytical theories; data science is about constructing models.</p>
<p>One of the talks that I recall is from a phd from Dubai about optimising maintenance scheduling in desalination plants. Desalination plants is big business in the Middle East as they provide a major source of fresh water there. However, components in these plants fail often because of the harsh condition that they work in and that servicing some of these components might need to bring the entire plant down for hours. The presenter proceeded to explain their method of using a Poisson process on the failure data to optimise maintenance work.</p>
<p>Now if it were me, I would add tons of sensors everywhere to enhance the frequency and granularity of data captured. Similar to what we do at work for web data. Then the problem practical solve itself as we'll be able to build predictive models for each and every crucial component. Using on-going data with these predictive models, we can flag high risk components and service them before they cause trouble.</p>
<p>The problem is that adding sensors is not trivial (from my electrical engineering days) in a physical system. The high cost of installing all of that and the questionable efficacy of measurements make getting data a challenge. For problems like this, I can see where a traditional scientific thinking of using sparse data to support theories is practical.</p>
<p>Yet, not everything can be reduced to formulas and solved analytically. As this blog piece on Scientific American points out, <a href="http://blogs.scientificamerican.com/the-curious-wavefunction/2012/09/05/theories-models-and-the-future-of-science/">science is moving towards solving problems computationally</a>. So too are the industries as we've seen examples from Amazon and LinkedIn driving massive sales by modelling and enabling a feedback loop with their data.</p>
<p>It's a shame that so many companies are poisoning the term Big Data these days by plastering it all over their marketing material to sell products with no substance. There are real strategic advantages to be reaped if companies can do it right.</p> </div>
            <div class="abbr published">
                Posted  <a href='http://www.quantisan.com/i-construct-models-not-theories/' title='2012-09-11T22:00:00'>11 September 2012</a> in <a href="http://www.quantisan.com/category/data-science/">data-science</a>.              
            </div>
        </article>
        <article class='listed'>
            <h1 class="title">
                <a href="http://www.quantisan.com/my-talk-at-or54-on-knowledge-discovery-with-web-log-data/" rel='bookmark'>My talk at OR54 on knowledge discovery with web log data</a>
            </h1>
            <div class="article-content"> <h3>Abstract</h3>
<p>Web log data contains a wealth of information about online visitors. We have a record of each and every 
customer interaction for the millions of visitors coming through each month at uSwitch.com. The challenge 
is to analyse this discrete time series, semi-structured dataset to understand the behaviour of our visitors on 
a personal level. This talk is a case study of how our data team of three leveraged heterogeneous 
architecture and agile methodologies to tackle this problem. And we had three months.</p>
<h3>Slides</h3>
<iframe src="http://www.slideshare.net/slideshow/embed_code/14168871?hostedIn=slideshare&page=upload" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe> </div>
            <div class="abbr published">
                Posted  <a href='http://www.quantisan.com/my-talk-at-or54-on-knowledge-discovery-with-web-log-data/' title='2012-09-04T16:30:00'>04 September 2012</a> in <a href="http://www.quantisan.com/category/data-science/">data-science</a>.              
            </div>
        </article>
<p class="paginator">
                    <a href="http://www.quantisan.com/category/data-science//index2.html" class="button_accent" style="position: absolute; right: 0;">continue&nbsp;&nbsp;&nbsp;&rarr;</a>
</p>
    </section>

<script type="text/javascript">
	var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
	document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
	</script>
	<script type="text/javascript">
		try {
			var pageTracker = _gat._getTracker("UA-2047602-4");
			pageTracker._trackPageview();
		} catch(err) {}</script>
</body>
</html>