<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Quantitative Artisan</title><link href="http://www.quantisan.com/" rel="alternate"></link><link href="http://www.quantisan.com/feeds/tag/conference_atom.xml" rel="self"></link><id>http://www.quantisan.com/</id><updated>2012-09-11T22:00:00+01:00</updated><entry><title>I construct models, not theories</title><link href="http://www.quantisan.com/i-construct-models-not-theories/" rel="alternate"></link><updated>2012-09-11T22:00:00+01:00</updated><author><name>Paul Lam</name></author><id>tag:www.quantisan.com,2012-09-11:i-construct-models-not-theories/</id><summary type="html">&lt;p&gt;I &lt;a href="http://www.quantisan.com/my-talk-at-or54-on-knowledge-discovery-with-web-log-data/"&gt;gave a talk&lt;/a&gt; at the 54th Annual Conference on Operational Research last week in Edinburgh. Operational Research is "using advanced analytical methods to help make better decisions" [&lt;a href="https://en.wikipedia.org/wiki/Operation_research"&gt;wiki&lt;/a&gt;]. This field has been around long before data science and business intelligence. After listening to so many talks and talking to so many academics from marketing to finance to industrial engineering, I find that what we do are quite similar on a 30 thousand feet level -- using data to solve problems. Yet, there is a fundamental difference to our approaches. Whereas operational research is about constructing analytical theories; data science is about constructing models.&lt;/p&gt;
&lt;p&gt;One of the talks that I recall is from a phd from Dubai about optimising maintenance scheduling in desalination plants. Desalination plants is big business in the Middle East as they provide a major source of fresh water there. However, components in these plants fail often because of the harsh condition that they work in and that servicing some of these components might need to bring the entire plant down for hours. The presenter proceeded to explain their method of using a Poisson process on the failure data to optimise maintenance work.&lt;/p&gt;
&lt;p&gt;Now if it were me, I would add tons of sensors everywhere to enhance the frequency and granularity of data captured. Similar to what we do at work for web data. Then the problem practical solve itself as we'll be able to build predictive models for each and every crucial component. Using on-going data with these predictive models, we can flag high risk components and service them before they cause trouble.&lt;/p&gt;
&lt;p&gt;The problem is that adding sensors is not trivial (from my electrical engineering days) in a physical system. The high cost of installing all of that and the questionable efficacy of measurements make getting data a challenge. For problems like this, I can see where a traditional scientific thinking of using sparse data to support theories is practical.&lt;/p&gt;
&lt;p&gt;Yet, not everything can be reduced to formulas and solved analytically. As this blog piece on Scientific American points out, &lt;a href="http://blogs.scientificamerican.com/the-curious-wavefunction/2012/09/05/theories-models-and-the-future-of-science/"&gt;science is moving towards solving problems computationally&lt;/a&gt;. So too are the industries as we've seen examples from Amazon and LinkedIn driving massive sales by modelling and enabling a feedback loop with their data.&lt;/p&gt;
&lt;p&gt;It's a shame that so many companies are poisoning the term Big Data these days by plastering it all over their marketing material to sell products with no substance. There are real strategic advantages to be reaped if companies can do it right.&lt;/p&gt;</summary><category term="conference"></category></entry></feed>