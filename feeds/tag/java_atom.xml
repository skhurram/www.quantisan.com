<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Paul Lam</title><link href="http://www.quantisan.com/" rel="alternate"></link><link href="http://www.quantisan.com/feeds/tag/java_atom.xml" rel="self"></link><id>http://www.quantisan.com/</id><updated>2011-06-15T20:50:00-04:00</updated><entry><title>It's an open buffet in a small business</title><link href="http://www.quantisan.com/its-an-open-buffet-in-a-small-business/" rel="alternate"></link><updated>2011-06-15T20:50:00-04:00</updated><author><name>Paul Lam</name></author><id>tag:www.quantisan.com,2011-06-15:its-an-open-buffet-in-a-small-business/</id><summary type="html">&lt;p&gt;One of the few benefits of working for myself is that I don't need to
worry about compatibility with legacy systems. I am free to use whatever
open source tools to get the job done well. The downside to this is that
there are so many technologies out there that it's hard to choose the
right ones for the job. To give you a sense of what I meant, here are
some of the topics that I have either tried or seriously considered in
the past year.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Programming languages: &lt;a href="http://www.quantisan.com/tag/java/"&gt;Java&lt;/a&gt;, &lt;a href="http://www.quantisan.com/tag/python/"&gt;Python&lt;/a&gt;, &lt;a href="http://www.quantisan.com/tag/R"&gt;R&lt;/a&gt;, C#, F#, Scala,
    Clojure, Haskell.&lt;/li&gt;
&lt;li&gt;Data storage: &lt;a href="http://www.quantisan.com/from-object-oriented-programming-to-object-oriented-design/"&gt;HDF5&lt;/a&gt;, CSV, Binary, MySQL, PostgreSQL, MongoDB,
    MonetDB, Redis, HBase.&lt;/li&gt;
&lt;li&gt;Cloud server: &lt;a href="http://www.quantisan.com/tag/amazon-ec2/"&gt;Amazon EC2&lt;/a&gt;, Microsoft Azure, [Google App
    Engine][], Rackspace Cloud, &lt;a href="http://www.quantisan.com/tag/vps/"&gt;plain old VPSs&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Programming language choices are important because they sit at the
bottom of a technology stack. Most of the work that I do are built on
using them. For a long while, I settled on using a combination of Java,
Python, and R. I prototype small ideas in Python. Implement production
code in Java. And perform analysis in R. I discussed why &lt;a href="http://www.quantisan.com/data-analysis-with-r-using-the-right-tool-for-the-right-task/"&gt;use the right
tool for the right task&lt;/a&gt; a year ago. By the end of my previous
project, I am finding that the popular development triplet of Java,
Python, and R, is not ideal for a solo-operation. Seeing that I have
more time on my hands because I am using QTD to trade for me now, I am
taking a break this summer to expand my knowledge and learn new
technologies. Some of the technologies that I am experimenting with
includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;an in-memory data store for instantaneous and persistent tick data&lt;/li&gt;
&lt;li&gt;parallel programming for concurrent processing with no locks&lt;/li&gt;
&lt;li&gt;mathematically intuitive algorithm implementations using high order
    functions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Don't mind me as I help myself in this open buffet of technologies.&lt;/p&gt;
&lt;/p&gt;</summary><category term="java"></category><category term="python"></category><category term="R"></category></entry><entry><title>A brief comparison of double arrays for high-performance numerical computing in Java</title><link href="http://www.quantisan.com/a-brief-comparison-of-double-arrays-for-high-performance-numerical-computing-in-java/" rel="alternate"></link><updated>2010-11-01T09:12:00-04:00</updated><author><name>Paul Lam</name></author><id>tag:www.quantisan.com,2010-11-01:a-brief-comparison-of-double-arrays-for-high-performance-numerical-computing-in-java/</id><summary type="html">&lt;p&gt;Numerical calculation performance matters if you're calculating gigantic
datasets or have limited processing capability. I belong in the latter
case as I intend to run my trading system on &lt;a href="http://www.quantisan.com/rev-your-trading-system-on-the-cloud-with-a-free-amazon-cloud-server/"&gt;a free cloud server&lt;/a&gt; in
the future. There are plenty of research and studies to push the
boundary of high-performance numerical computing in Java (see ref. 1 and
2). Most of the latest and greatest is beyond the scope of my
quantitative work. What I seek is performance with simplicity and
efficiency. That is how I became aware of the &lt;a href="http://acs.lbl.gov/software/colt/"&gt;Colt Project&lt;/a&gt; by CERN,
and its &lt;a href="http://sites.google.com/site/piotrwendykier/software/parallelcolt"&gt;multi-threaded branch&lt;/a&gt;. Colt is a set of open source Java
libraries for scientific and technical computing problems characterized
by large data sizes while demanding high performance and low memory
footprint. Just what I needed. Out of curiosity, I tested its
implementation of double arrays and compared its performance to standard
Java libraries.&lt;/p&gt;
&lt;h2&gt;Method&lt;/h2&gt;
&lt;p&gt;A random sample of a million decimal values (e.g. prices) are generated
and stored in four Java data structures. All data structures have the
same one million values in their own respective memory spaces.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Primitive double array&lt;/li&gt;
&lt;li&gt;ArrayList of Double objects&lt;/li&gt;
&lt;li&gt;Colt&lt;/li&gt;
&lt;li&gt;Parallel Colt&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Three tests were ran.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A simple &lt;em&gt;diff&lt;/em&gt; function. A traversal of the million data points and
    calculating array[i] - array[i - shift] for all &lt;em&gt;i = shift to
    1,000,000&lt;/em&gt;. Where &lt;em&gt;shift&lt;/em&gt; is a random integer from 0 to 50. This
    type of calculation is common place in technical analysis
    indicators.&lt;/li&gt;
&lt;li&gt;A sort function sorting the million data points in the array in
    ascending order. This come in handy for some statistical analysis.
    In the case of the primitive array, I am using
    java.util.Arrays.sort(). Otherwise I'm using the sort() method
    implicit in the other interfaces.&lt;/li&gt;
&lt;li&gt;A binary search function on the sorted arrays. For the primitive
    array, I am using java.util.Arrays.binarySearch().&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each test is ran 3 times with different random seeds and the results are
averaged. The system runs Java SE build 1.6.0_22-b04 and Linux kernel
2.6.35-22 on an Intel Core 2 Duo 6300 @ 1.86 GHz.&lt;/p&gt;
&lt;h2&gt;Result&lt;/h2&gt;
&lt;p&gt;For the diff, primitive array averaged 9.3 millisecond; ArrayList 27
ms.; Colt 14 ms.; Parallel Colt 15 ms. For sort, primitive 354.7 ms.;
ArrayList 1,316 ms.; Colt 270.3 ms.; Parallel Colt 273 ms. For search,
primitive 559.7 ms.; ArrayList 1,561.7 ms.; Colt 575.7 ms.; Parallel
Colt 551.3 ms.&lt;/p&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;As this isn't a vigorous test, I wouldn't mind too much on the actual
numbers. The take home message here is that the performance of Colt is
at least in the same magnitude of a primitive array. Whereas a standard
ArrayList object is a magnitude worse. However, where Colt really shines
is in its methods for handling matrices. It offers plenty of convenient
functions for matrix calculations while guaranteeing good performance.
To work with matrices in Java, you either use third-party libraries such
as Colt or manage a bunch of &lt;em&gt;for&lt;/em&gt; loops. Which isn't pretty.&lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;[1] Moreira, et al., &lt;/span&gt;"Java programming for
high-performance numerical computing," IBM Systems Journal, Vol. 39,
No. 1, pp. 21-56, 2000. [2] Wendykier and Nagy, "Parallel Colt: A
High-Performance Java Library for Scientific Computing and Image
Processing," ACM Transactions on Mathematical Software, Vol. 37, No. 3,
September 2010.&lt;/p&gt;
&lt;/p&gt;</summary><category term="java"></category></entry></feed>